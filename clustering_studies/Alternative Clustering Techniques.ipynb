{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import sequenceanalyzer as sa\n",
    "import partition as pt\n",
    "import partitionset as ps\n",
    "import sequence_generator as sg\n",
    "import dmarkov as dm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans as k\n",
    "import save_plot as sp\n",
    "import eigenvectorcalcs as eig\n",
    "import moore\n",
    "sys.path.insert(0, 'Code')\n",
    "# import kmeans as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_map(x0 = 0.5, r = 3.75):\n",
    "    x = [x0]\n",
    "    s = ''\n",
    "    for i in range(10000000):\n",
    "        x.append(r*x[i]*(1-x[i]))\n",
    "        if x[i] <= 0.67:\n",
    "             s += '0'\n",
    "        elif x[i] <= 0.79:\n",
    "             s += '1'\n",
    "        else:\n",
    "             s += '2'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-37304249952d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# os.makedirs('logistic_map/machine')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# os.makedirs('logistic_map/probabilities/conditional')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logistic_map/sequences/lm_10000000.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic_map' is not defined"
     ]
    }
   ],
   "source": [
    "# os.makedirs('logistic_map/sequences')\n",
    "# os.makedirs('logistic_map/machine')\n",
    "# os.makedirs('logistic_map/probabilities/conditional')\n",
    "s = logistic_map()\n",
    "\n",
    "with open('logistic_map/sequences/lm_10000000.yaml', 'w') as f:\n",
    "    yaml.dump(s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('logistic_map/sequences/lm_10000000.yaml', 'r') as f:\n",
    "    s = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating probabilities for words with length 11 ...\n",
      "Calculating probabilities for words with length 10 ...\n",
      "Calculating probabilities for words with length 9 ...\n",
      "Calculating probabilities for words with length 8 ...\n",
      "Calculating probabilities for words with length 7 ...\n",
      "Calculating probabilities for words with length 6 ...\n",
      "Calculating probabilities for words with length 5 ...\n",
      "Calculating probabilities for words with length 4 ...\n",
      "Calculating probabilities for words with length 3 ...\n",
      "Calculating probabilities for words with length 2 ...\n",
      "Calculating subsequence conditional probabilities\n",
      "L = 5\n",
      "Calculating conditional probabilities of subsequences of length: 1\n",
      "Calculating conditional probabilities of subsequences of length: 2\n",
      "Calculating conditional probabilities of subsequences of length: 3\n",
      "Calculating conditional probabilities of subsequences of length: 4\n",
      "Calculating conditional probabilities of subsequences of length: 5\n",
      "*****************\n",
      "Conditional probabilities calculated!\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "p, a = sa.calc_probs(s, 10)\n",
    "p_cond = sa.calc_cond_probs(p, a, 5)\n",
    "\n",
    "with open('logistic_map/probabilities/lm_10000000.yaml', 'w') as f:\n",
    "    yaml.dump(p, f)\n",
    "with open('logistic_map/probabilities/conditional/lm_10000000.yaml', 'w') as f:\n",
    "    yaml.dump(p_cond, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = dm.DMarkov(p_cond, 4, a, p)\n",
    "len(m.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0020\n",
      "[('2', '0202', 1.0)]\n",
      "\n",
      "0200\n",
      "[('2', '2002', 1.0)]\n",
      "\n",
      "0202\n",
      "[('0', '2020', 1.0)]\n",
      "\n",
      "0201\n",
      "[('0', '2010', 0.10968483560021094), ('1', '2011', 0.5061025023943421), ('2', '2012', 0.38421266200544696)]\n",
      "\n",
      "0102\n",
      "[('0', '1020', 1.0)]\n",
      "\n",
      "0120\n",
      "[('2', '1202', 1.0)]\n",
      "\n",
      "0110\n",
      "[('2', '1102', 1.0)]\n",
      "\n",
      "0112\n",
      "[('0', '1120', 1.0)]\n",
      "\n",
      "0111\n",
      "[('0', '1110', 0.18592943085034475), ('1', '1111', 0.5710747600378533), ('2', '1112', 0.24299580911180213)]\n",
      "\n",
      "2002\n",
      "[('0', '0020', 1.0)]\n",
      "\n",
      "2020\n",
      "[('0', '0200', 0.2324569222273915), ('1', '0201', 0.37181498406459385), ('2', '0202', 0.39572809370801465)]\n",
      "\n",
      "2010\n",
      "[('2', '0102', 1.0)]\n",
      "\n",
      "2012\n",
      "[('0', '0120', 1.0)]\n",
      "\n",
      "2011\n",
      "[('0', '0110', 0.43114312055066095), ('1', '0111', 0.42728673787919746), ('2', '0112', 0.14157014157014158)]\n",
      "\n",
      "1020\n",
      "[('2', '0202', 1.0)]\n",
      "\n",
      "1202\n",
      "[('0', '2020', 1.0)]\n",
      "\n",
      "1102\n",
      "[('0', '1020', 1.0)]\n",
      "\n",
      "1120\n",
      "[('2', '1202', 1.0)]\n",
      "\n",
      "1110\n",
      "[('2', '1102', 1.0)]\n",
      "\n",
      "1112\n",
      "[('0', '1120', 1.0)]\n",
      "\n",
      "1111\n",
      "[('0', '1110', 0.21032626553138323), ('1', '1111', 0.5716076376071427), ('2', '1112', 0.21806609686147407)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for st in m.states:\n",
    "    print(st.name)\n",
    "    print(st.outedges)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dict((s.name, m.states.index(s)) for s in m.states)\n",
    "morphs = []\n",
    "all_oedges = [state.outedges for state in m.states]\n",
    "\n",
    "for oedges in all_oedges:\n",
    "    curr_morph = [0] * len(m.index_labels)\n",
    "    for oedge in oedges:\n",
    "        label = oedge[0]\n",
    "        curr_morph[m.index_labels[label]] = oedge[-1]\n",
    "    morphs.append(curr_morph)\n",
    "    \n",
    "morphs = np.array(morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = morphs.T\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncenters = 5\n",
    "\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data, ncenters, 2, error=0.005, maxiter=1000, init=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1]), array([1]), array([0]), array([2, 4]), array([0]), array([1]), array([1]), array([0]), array([4]), array([0]), array([2]), array([1]), array([0]), array([3]), array([1]), array([0]), array([0]), array([1]), array([1]), array([0]), array([4])]\n"
     ]
    }
   ],
   "source": [
    "u[u < 1e-03] = 0\n",
    "w = u.T\n",
    "closest_cluster = []\n",
    "maxlen = 0\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "for i in w:\n",
    "    c = np.where(i > 0.1)[-1]\n",
    "    if len(c) > 1:\n",
    "        maxlen \n",
    "    closest_cluster.append(np.array(c))\n",
    "    \n",
    "print(closest_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "clusters = [[]]\n",
    "\n",
    "for i in closest_cluster:\n",
    "    if len(i) > 1:\n",
    "        n = len(i)\n",
    "        new_clusters = []\n",
    "        for idx in i:\n",
    "            temp = copy.deepcopy(clusters)\n",
    "            for j in range(len(temp)):\n",
    "                temp[j].append(idx)\n",
    "                new_clusters.append(temp[j])\n",
    "#             print(new_clusters)\n",
    "        clusters = copy.deepcopy(new_clusters)\n",
    "#         print(new_clusters)\n",
    "    elif len(i) == 1:\n",
    "        idx = i[0]\n",
    "        for j in range(len(clusters)):\n",
    "            clusters[j].append(idx)\n",
    "#             print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_clusters = copy.deepcopy(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0, 2, 0, 1, 1, 0, 4, 0, 2, 1, 0, 3, 1, 0, 0, 1, 1, 0, 4],\n",
       " [1, 1, 0, 4, 0, 1, 1, 0, 4, 0, 2, 1, 0, 3, 1, 0, 0, 1, 1, 0, 4]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do: generate different \"cluster\" arrays with the combinations of clusters from c-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0202: [('0', '2020', 1.0)]\n",
      "0102: [('0', '1020', 1.0)]\n",
      "0112: [('0', '1120', 1.0)]\n",
      "2002: [('0', '0020', 1.0)]\n",
      "2012: [('0', '0120', 1.0)]\n",
      "1202: [('0', '2020', 1.0)]\n",
      "1102: [('0', '1020', 1.0)]\n",
      "1112: [('0', '1120', 1.0)]\n",
      "\n",
      "0020: [('2', '0202', 1.0)]\n",
      "0200: [('2', '2002', 1.0)]\n",
      "0120: [('2', '1202', 1.0)]\n",
      "0110: [('2', '1102', 1.0)]\n",
      "2010: [('2', '0102', 1.0)]\n",
      "1020: [('2', '0202', 1.0)]\n",
      "1120: [('2', '1202', 1.0)]\n",
      "1110: [('2', '1102', 1.0)]\n",
      "\n",
      "0201: [('0', '2010', 0.10968483560021094), ('1', '2011', 0.5061025023943421), ('2', '2012', 0.38421266200544696)]\n",
      "2020: [('0', '0200', 0.2324569222273915), ('1', '0201', 0.37181498406459385), ('2', '0202', 0.39572809370801465)]\n",
      "\n",
      "2011: [('0', '0110', 0.43114312055066095), ('1', '0111', 0.42728673787919746), ('2', '0112', 0.14157014157014158)]\n",
      "\n",
      "0111: [('0', '1110', 0.18592943085034475), ('1', '1111', 0.5710747600378533), ('2', '1112', 0.24299580911180213)]\n",
      "1111: [('0', '1110', 0.21032626553138323), ('1', '1111', 0.5716076376071427), ('2', '1112', 0.21806609686147407)]\n",
      "\n",
      "end of partition\n",
      "\n",
      "\n",
      "0202: [('0', '2020', 1.0)]\n",
      "0102: [('0', '1020', 1.0)]\n",
      "0112: [('0', '1120', 1.0)]\n",
      "2002: [('0', '0020', 1.0)]\n",
      "2012: [('0', '0120', 1.0)]\n",
      "1202: [('0', '2020', 1.0)]\n",
      "1102: [('0', '1020', 1.0)]\n",
      "1112: [('0', '1120', 1.0)]\n",
      "\n",
      "0020: [('2', '0202', 1.0)]\n",
      "0200: [('2', '2002', 1.0)]\n",
      "0120: [('2', '1202', 1.0)]\n",
      "0110: [('2', '1102', 1.0)]\n",
      "2010: [('2', '0102', 1.0)]\n",
      "1020: [('2', '0202', 1.0)]\n",
      "1120: [('2', '1202', 1.0)]\n",
      "1110: [('2', '1102', 1.0)]\n",
      "\n",
      "2020: [('0', '0200', 0.2324569222273915), ('1', '0201', 0.37181498406459385), ('2', '0202', 0.39572809370801465)]\n",
      "\n",
      "2011: [('0', '0110', 0.43114312055066095), ('1', '0111', 0.42728673787919746), ('2', '0112', 0.14157014157014158)]\n",
      "\n",
      "0201: [('0', '2010', 0.10968483560021094), ('1', '2011', 0.5061025023943421), ('2', '2012', 0.38421266200544696)]\n",
      "0111: [('0', '1110', 0.18592943085034475), ('1', '1111', 0.5710747600378533), ('2', '1112', 0.24299580911180213)]\n",
      "1111: [('0', '1110', 0.21032626553138323), ('1', '1111', 0.5716076376071427), ('2', '1112', 0.21806609686147407)]\n",
      "\n",
      "end of partition\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def imprime_clusters(cluster):\n",
    "    for c in cluster:\n",
    "        for st in c:\n",
    "            print(f'{st.name}: {st.outedges}')\n",
    "        print()\n",
    "    print('end of partition\\n\\n')\n",
    "\n",
    "for closest_cluster in closest_clusters:\n",
    "    clusters = [[] for i in closest_cluster]\n",
    "    # print(f\"Clusterization check\")\n",
    "\n",
    "    for i in range(len(morphs)):\n",
    "        cluster_index = closest_cluster[i]\n",
    "        # print(f\"\\tCenter: {kmeans.cluster_centers_[state_idx]}, Outedge: {machine.states[i].outedges}\")\n",
    "        clusters[cluster_index].append(m.states[i])\n",
    "    # Fix empty clusters problem\n",
    "    clusters = [c for c in clusters if c]\n",
    "    imprime_clusters(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b), axis=1)\n",
    "\n",
    "# def dist(a, b):\n",
    "#     eps = 1e-15\n",
    "#     a = np.array(a, dtype='float64')\n",
    "#     b = np.array(b, dtype='float64')\n",
    "#     a[a == 0] = eps\n",
    "#     b[b == 0] = eps\n",
    "#     kl = (a*np.log(a/b) + b*np.log(b/a))/2\n",
    "    \n",
    "#     if a.shape != b.shape:\n",
    "#         return np.sum(kl, axis = 0)\n",
    "#     if a.shape == b.shape:\n",
    "#         return np.sum(kl, axis = 1)\n",
    "\n",
    "# def dist(vec1, vec2):\n",
    "#     kl = [0, 0]\n",
    "#     print(\"Calculating Kullback-Leibler divergence\")\n",
    "#     if len(vec1) and len(vec1) == len(vec2):\n",
    "#         #Probabilities of subsequences of length K are stored in probabilities[K-1]\n",
    "#         for i in range(len(vec1)):\n",
    "#             p = vec1[i] or 1e-15\n",
    "#             q = vec2[i] or 1e-15\n",
    "#             # print(f'p={p}, q={q}')\n",
    "#             kl[0] += p*np.log2(p/q)\n",
    "#             kl[1] += p*np.log2(p/q)\n",
    "#     else:\n",
    "#         print (\"[error] Probabilities not computed.\")\n",
    "#     print(\"*****************\")\n",
    "#     print(\"Kullback-Leibler divergence calculated!\")\n",
    "#     print(\"*****************\")\n",
    "#     return (kl[0]+kl[1])/2\n",
    "\n",
    "def custom_kmeans(matrix, k, centroids):\n",
    "    current_centroids = np.array(centroids)\n",
    "    matrix = np.array(matrix)\n",
    "    previous_centroids = np.zeros(current_centroids.shape)\n",
    "\n",
    "    error = dist(current_centroids, previous_centroids)\n",
    "    nearest_clusters = np.zeros(len(matrix))\n",
    "    print('~~~ Starting K-Means ~~~')\n",
    "    while sum(error) > 0.01:\n",
    "        print(f'Error = {sum(error)}')\n",
    "        for i in range(len(matrix)):\n",
    "            distances = dist(matrix[i], current_centroids)\n",
    "            nearest_clusters[i] = np.argmin(distances)\n",
    "            print(f'Distance to centroids : {distances}\\n Nearest_cluster: {nearest_clusters[i]}\\n')\n",
    "\n",
    "            previous_centroids = current_centroids.copy()\n",
    "\n",
    "        for i in range(k):\n",
    "            current_centroids[i] = np.mean(matrix[np.where(nearest_clusters == i)], axis=0)\n",
    "        print(f'New centroids: {current_centroids}\\n Old centroids: {previous_centroids}\\n\\n')\n",
    "\n",
    "        error = dist(current_centroids, previous_centroids)\n",
    "    return (nearest_clusters, current_centroids)\n",
    "\n",
    "def get_center(features, target):\n",
    "    target_set = set(target)\n",
    "    return np.array([np.mean(features[np.where(target == i)], 0) for i in range(len(target_set))])\n",
    "\n",
    "def get_initial_centroids(samples = [], K = 5):\n",
    "    i = 0\n",
    "    centroids = []\n",
    "\n",
    "    for sample in samples:\n",
    "        if sample not in centroids:\n",
    "            centroids.append(sample)\n",
    "            i += 1\n",
    "        if i == K:\n",
    "            return np.array(centroids)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', '11110', 0.2057681799149818),\n",
       " ('1', '11111', 0.5714032261498393),\n",
       " ('2', '11112', 0.22282859393517895)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.states[0].outedges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
